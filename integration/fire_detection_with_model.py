import json
import os
import time
import requests
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.serialization import SimpleStringSchema
from pyflink.common.typeinfo import Types
from pyflink.datastream.connectors import FlinkKafkaConsumer, FlinkKafkaProducer
from pyflink.common import Configuration

# TorchServe API ç«¯ç‚¹
TORCHSERVE_URL = "http://torchserve:8080/predictions/fire_detector"  # ä½¿ç”¨DockeræœåŠ¡å

def call_model_api(data):
    """
    è°ƒç”¨TorchServe APIè¿›è¡Œé¢„æµ‹
    """
    try:
        response = requests.post(
            TORCHSERVE_URL,
            data=data,
            headers={"Content-Type": "application/json"}
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: HTTP {response.status_code}, {response.text}")
            return None
    except Exception as e:
        print(f"âŒ è¯·æ±‚æ¨¡å‹APIå‡ºé”™: {e}")
        return None

def process_data_with_model(data):
    """
    å¤„ç†æ•°æ®å¹¶è°ƒç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
    """
    print(f"ğŸŸ¡ æ­£åœ¨å¤„ç†æ•°æ®: {data}")
    
    try:
        # è§£æè¾“å…¥æ•°æ®
        record = json.loads(data)
        temperature = float(record.get('temperature', 0.0))
        humidity = float(record.get('humidity', 0.0))
        smoke = float(record.get('smoke', 0.0))
        device_id = record.get('device_id', 'unknown')
        timestamp = record.get('timestamp', '')
        
        # è¿‡æ»¤å¼‚å¸¸æ•°æ®
        is_abnormal = temperature > 60.0 or smoke > 0.8
        
        # åªæœ‰å¼‚å¸¸æ•°æ®æ‰å‘é€åˆ°æ¨¡å‹
        if is_abnormal:
            # è°ƒç”¨æ¨¡å‹API
            model_result = call_model_api(data)
            
            if model_result:
                # åˆå¹¶æ¨¡å‹é¢„æµ‹ç»“æœä¸åŸå§‹æ•°æ®
                result = {
                    'timestamp': timestamp,
                    'device_id': device_id,
                    'temperature': temperature,
                    'humidity': humidity,
                    'smoke': smoke,
                    'is_abnormal': is_abnormal,
                    'model_prediction': model_result,
                    'alert_level': model_result.get('risk_level', 'HIGH')
                }
            else:
                # å¦‚æœæ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨åŸºæœ¬é€»è¾‘
                result = {
                    'timestamp': timestamp,
                    'device_id': device_id,
                    'temperature': temperature,
                    'humidity': humidity,
                    'smoke': smoke,
                    'is_abnormal': is_abnormal,
                    'alert_level': 'HIGH',
                    'model_failed': True
                }
                
            print(f"âœ… å¤„ç†å®Œæˆ: {result}")
            return json.dumps(result)
        else:
            # æ­£å¸¸æ•°æ®ä¸å¤„ç†
            return None
            
    except Exception as e:
        print(f"âŒ é”™è¯¯å¤„ç†æ•°æ®: {e}")
        return json.dumps({
            'error': f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}",
            'original_data': data
        })

def main():
    print("ğŸš€ åˆå§‹åŒ– Flink ç¯å¢ƒ...")
    env = StreamExecutionEnvironment.get_execution_environment()
    env.set_parallelism(1)
    
    print("ğŸ”Œ è®¾ç½® Kafka Source...")
    kafka_consumer = FlinkKafkaConsumer(
        topics='flink-input',
        deserialization_schema=SimpleStringSchema(),
        properties={
            'bootstrap.servers': 'kafka:9092',
            'group.id': 'fire-detection-group'
        }
    )
    
    print("ğŸ¯ è®¾ç½® Kafka Sink...")
    kafka_producer = FlinkKafkaProducer(
        topic='model-output',  # ä½¿ç”¨æ–°çš„ä¸»é¢˜å­˜å‚¨æ¨¡å‹å¤„ç†åçš„ç»“æœ
        serialization_schema=SimpleStringSchema(),
        producer_config={
            'bootstrap.servers': 'kafka:9092',
            'transaction.timeout.ms': '5000'
        }
    )
    
    print("ğŸ” ç»‘å®šæ•°æ®æµ...")
    data_stream = env.add_source(kafka_consumer)
    
    # ä½¿ç”¨æ¨¡å‹å¤„ç†æ•°æ®
    processed_stream = data_stream.map(
        process_data_with_model, 
        output_type=Types.STRING()
    ).filter(lambda x: x is not None)  # è¿‡æ»¤æ­£å¸¸æ•°æ®
    
    # å°†ç»“æœå‘é€åˆ°Kafka
    processed_stream.add_sink(kafka_producer)
    
    # å°è¯•å¤šæ¬¡å¯åŠ¨æ‰§è¡Œè®¡åˆ’ï¼ˆå¤„ç†ç½‘ç»œé—®é¢˜ï¼‰
    max_retries = 10
    for attempt in range(max_retries):
        try:
            print("ğŸ å¯åŠ¨æ‰§è¡Œè®¡åˆ’...")
            env.execute("Fire Detection with Model Integration Job")
            print("âœ… Flink ä½œä¸šæ‰§è¡Œå®Œæ¯•ï¼")
            break
        except Exception as e:
            print(f"âš ï¸ å¯åŠ¨å¤±è´¥ï¼Œç¬¬ {attempt + 1} æ¬¡å°è¯•: {e}")
            time.sleep(10)
    else:
        print("âŒ å¤šæ¬¡å°è¯•åä»æœªæˆåŠŸå¯åŠ¨ Flink Job")

if __name__ == '__main__':
    print("ğŸ“„ å¯åŠ¨ fire_detection_with_model.py è„šæœ¬")
    main()
