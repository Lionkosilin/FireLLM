# TorchServe Configuration

# 指定绑定到所有接口
inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
metrics_address=http://0.0.0.0:8082

# 确保启用指标
enable_metrics_api=true
metrics_format=prometheus

# Model store location
model_store=/home/model-server/model-store

# 自动加载模型配置（load_models 可省略，用 --models 指定 YAML）
# load_models=vlm_model=vlm_model.mar

# Set preferred direct memory size (in bytes)
number_of_netty_threads=32
job_queue_size=1000

# 关闭鉴权（推荐在这里配置）
disable_token_authorization=true
enable_envvars_config=true